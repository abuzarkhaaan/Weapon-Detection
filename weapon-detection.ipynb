{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:06:25.012045Z","iopub.status.busy":"2024-10-16T07:06:25.011636Z","iopub.status.idle":"2024-10-16T07:06:45.727367Z","shell.execute_reply":"2024-10-16T07:06:45.726211Z","shell.execute_reply.started":"2024-10-16T07:06:25.012005Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics 8.3.13 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n","Setup complete ✅ (4 CPUs, 31.4 GB RAM, 5933.9/8062.4 GB disk)\n"]}],"source":["%pip install ultralytics\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:06:49.684923Z","iopub.status.busy":"2024-10-16T07:06:49.684316Z","iopub.status.idle":"2024-10-16T07:07:05.481642Z","shell.execute_reply":"2024-10-16T07:07:05.480365Z","shell.execute_reply.started":"2024-10-16T07:06:49.684874Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: wandb 0.18.3\n","Uninstalling wandb-0.18.3:\n","  Successfully uninstalled wandb-0.18.3\n"]}],"source":["!pip uninstall -y wandb"]},{"cell_type":"markdown","metadata":{},"source":["**Training a Model**"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:08:44.307087Z","iopub.status.busy":"2024-10-16T07:08:44.306605Z","iopub.status.idle":"2024-10-16T08:53:32.925521Z","shell.execute_reply":"2024-10-16T08:53:32.924255Z","shell.execute_reply.started":"2024-10-16T07:08:44.307034Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n","100%|███████████████████████████████████████| 21.5M/21.5M [00:00<00:00, 138MB/s]\n","Ultralytics 8.3.13 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/kaggle/input/new-weapon-dataset/New_Dataset/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 13.9MB/s]\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n","Model summary: 249 layers, 9,839,347 parameters, 9,839,331 gradients, 23.6 GFLOPs\n","\n","Transferred 313/391 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","100%|██████████████████████████████████████| 5.35M/5.35M [00:00<00:00, 64.5MB/s]\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/new-weapon-dataset/New_Dataset/train/labels... 527\u001b[0m\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/new-weapon-dataset/New_Dataset/train is not writeable, cache not saved.\n","/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/new-weapon-dataset/New_Dataset/valid/labels... 2609 \u001b[0m\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/new-weapon-dataset/New_Dataset/valid is not writeable, cache not saved.\n","WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1, len(boxes) = 3101. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n","Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 70 weight(decay=0.0005), 69 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 4 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/50      5.01G      1.737      2.447      1.583         30        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.543      0.447      0.462      0.219\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/50       4.7G      1.869      2.002      1.734         17        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.609      0.494      0.526      0.258\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/50      4.96G      1.842      1.878      1.725         21        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.661      0.484      0.556      0.277\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/50       4.7G      1.781      1.729      1.681         30        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.818      0.557       0.67      0.361\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/50      4.97G      1.731      1.615      1.638         17        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.805      0.573      0.687      0.368\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/50      4.88G      1.676        1.5      1.607         14        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.784      0.617       0.72      0.391\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/50      4.86G      1.632      1.448      1.562         20        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101       0.83       0.62      0.734      0.423\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/50      4.88G      1.605       1.38      1.533         21        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.825      0.662       0.76      0.437\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/50      4.85G      1.579      1.344      1.524         18        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.822      0.648      0.751      0.428\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/50      4.98G       1.57      1.303      1.525         14        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.862       0.66      0.783      0.456\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/50      4.86G      1.536      1.259        1.5         19        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.841      0.703        0.8      0.463\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/50      4.69G       1.52      1.227      1.485         27        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.881      0.708      0.812       0.48\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/50      4.86G      1.507      1.194      1.465         19        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.877      0.716       0.82      0.481\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/50      4.87G      1.479      1.154      1.458         27        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.909      0.726      0.842      0.504\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/50      4.97G       1.47      1.129      1.441         23        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.878      0.718       0.83      0.498\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/50      4.87G       1.45      1.116      1.432         28        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.889      0.734      0.836      0.506\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/50      4.98G      1.432      1.079      1.426         29        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101       0.88      0.741      0.838      0.506\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/50      4.87G      1.426      1.057      1.414         21        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.896      0.734      0.838      0.515\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/50      4.85G      1.411      1.039      1.404         20        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.922      0.746      0.867      0.536\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/50      4.88G      1.378      1.016       1.38         32        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.902      0.738       0.84      0.516\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/50      4.86G      1.387      1.019      1.391         20        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.908      0.759      0.861      0.526\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/50      4.98G      1.376     0.9923      1.377         16        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.905      0.763      0.857      0.531\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/50      4.68G      1.354      1.002      1.372         21        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.872      0.781      0.872      0.539\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/50      4.69G      1.359      0.976      1.365         23        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.928      0.751      0.875      0.544\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      25/50      4.68G       1.34     0.9571      1.349         16        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.909       0.77      0.868      0.537\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      26/50      4.98G      1.332     0.9352      1.339         20        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.906      0.765      0.864       0.54\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      27/50      4.68G      1.326     0.9162      1.338         17        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.899      0.775      0.871      0.547\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      28/50      4.87G      1.327     0.9141      1.337         21        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.913       0.76      0.866      0.544\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      29/50      4.97G        1.3     0.8929       1.32         24        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.898      0.803      0.891      0.558\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      30/50      4.97G      1.288     0.8695      1.309         21        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101       0.92      0.774      0.887      0.561\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      31/50      4.86G      1.277     0.8699      1.295         27        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.918       0.78      0.884      0.557\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      32/50      4.68G      1.278     0.8576      1.302         23        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101       0.89        0.8      0.884      0.554\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      33/50      4.85G      1.259     0.8422      1.292         31        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.906      0.798      0.889      0.563\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      34/50      4.87G      1.258     0.8415      1.296         25        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.896      0.815      0.896      0.565\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      35/50      4.79G      1.245     0.8239      1.285         19        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.905      0.798      0.887      0.567\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      36/50      4.85G      1.226     0.8083      1.268         27        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.898      0.802       0.89      0.567\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      37/50      4.97G      1.213      0.799      1.261         28        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.897      0.804      0.892      0.571\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      38/50      4.87G      1.209     0.7763      1.261         20        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.907      0.807      0.891      0.566\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      39/50      4.97G      1.189     0.7643      1.243         29        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.904      0.805      0.888      0.573\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      40/50      4.88G      1.195     0.7608      1.247         26        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.914      0.792      0.894      0.574\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      41/50      4.85G      1.124     0.6028      1.215         14        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.912      0.814      0.897      0.578\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      42/50      4.98G      1.111     0.5814      1.206         15        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.916      0.805       0.89      0.578\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      43/50      4.86G      1.086     0.5692      1.191         15        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.902      0.818      0.895      0.578\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      44/50      4.68G      1.083     0.5536      1.183         18        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.913      0.805      0.892      0.578\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      45/50      4.77G      1.069     0.5404      1.176         14        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.903      0.811      0.888      0.578\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      46/50      4.87G      1.043     0.5279      1.157         14        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.903      0.825      0.895      0.583\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      47/50      4.78G      1.033      0.517      1.151         12        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.919      0.803      0.891      0.584\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      48/50      4.68G      1.025     0.5043      1.146         18        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.913      0.806      0.891      0.584\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      49/50      4.61G      1.019     0.4989      1.145         18        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101      0.897      0.821      0.891      0.586\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      50/50      4.67G      1.003     0.4982      1.138         18        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101       0.91      0.816      0.895      0.589\n","\n","50 epochs completed in 1.718 hours.\n","Optimizer stripped from runs/detect/train/weights/last.pt, 19.9MB\n","Optimizer stripped from runs/detect/train/weights/best.pt, 19.9MB\n","\n","Validating runs/detect/train/weights/best.pt...\n","Ultralytics 8.3.13 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n","Model summary (fused): 186 layers, 9,828,051 parameters, 0 gradients, 23.3 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2609       3101       0.91      0.815      0.894      0.589\n","Speed: 0.2ms preprocess, 4.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}],"source":["#Training a model according to mentioned epochs\n","!yolo detect train model=yolov8s.pt data= '/kaggle/input/new-weapon-dataset/New_Dataset/data.yaml' epochs=50 imgsz=640 batch=16"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Run inference on an image with YOLOv8n\n","!yolo predict model=\"/kaggle/working/runs/detect/train/weights/best.pt\" source='/kaggle/input/weapon-detection-test-dataset/Brazen robbery caught on video at SE Houston gas station.mp4'"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T08:54:04.728313Z","iopub.status.busy":"2024-10-16T08:54:04.727934Z","iopub.status.idle":"2024-10-16T08:54:08.399864Z","shell.execute_reply":"2024-10-16T08:54:08.398551Z","shell.execute_reply.started":"2024-10-16T08:54:04.728270Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/runs/detect/train/ (stored 0%)\n","  adding: kaggle/working/runs/detect/train/val_batch0_labels.jpg (deflated 7%)\n","  adding: kaggle/working/runs/detect/train/val_batch1_labels.jpg (deflated 11%)\n","  adding: kaggle/working/runs/detect/train/val_batch2_labels.jpg (deflated 7%)\n","  adding: kaggle/working/runs/detect/train/labels_correlogram.jpg (deflated 30%)\n","  adding: kaggle/working/runs/detect/train/weights/ (stored 0%)\n","  adding: kaggle/working/runs/detect/train/weights/best.pt (deflated 8%)\n","  adding: kaggle/working/runs/detect/train/weights/last.pt (deflated 8%)\n","  adding: kaggle/working/runs/detect/train/val_batch1_pred.jpg (deflated 10%)\n","  adding: kaggle/working/runs/detect/train/train_batch0.jpg (deflated 2%)\n","  adding: kaggle/working/runs/detect/train/val_batch0_pred.jpg (deflated 7%)\n","  adding: kaggle/working/runs/detect/train/F1_curve.png (deflated 18%)\n","  adding: kaggle/working/runs/detect/train/PR_curve.png (deflated 20%)\n","  adding: kaggle/working/runs/detect/train/val_batch2_pred.jpg (deflated 7%)\n","  adding: kaggle/working/runs/detect/train/results.png (deflated 7%)\n","  adding: kaggle/working/runs/detect/train/events.out.tfevents.1729062547.bc98840560f1.167.0 (deflated 90%)\n","  adding: kaggle/working/runs/detect/train/P_curve.png (deflated 19%)\n","  adding: kaggle/working/runs/detect/train/confusion_matrix_normalized.png (deflated 36%)\n","  adding: kaggle/working/runs/detect/train/train_batch13202.jpg (deflated 8%)\n","  adding: kaggle/working/runs/detect/train/results.csv (deflated 61%)\n","  adding: kaggle/working/runs/detect/train/R_curve.png (deflated 18%)\n","  adding: kaggle/working/runs/detect/train/train_batch13201.jpg (deflated 6%)\n","  adding: kaggle/working/runs/detect/train/train_batch1.jpg (deflated 2%)\n","  adding: kaggle/working/runs/detect/train/confusion_matrix.png (deflated 36%)\n","  adding: kaggle/working/runs/detect/train/train_batch13200.jpg (deflated 7%)\n","  adding: kaggle/working/runs/detect/train/labels.jpg (deflated 22%)\n","  adding: kaggle/working/runs/detect/train/args.yaml (deflated 52%)\n","  adding: kaggle/working/runs/detect/train/train_batch2.jpg (deflated 2%)\n"]}],"source":["# Compress a directory and its contents\n","!zip -r \"/kaggle/working/compressed_directory.zip\" \"/kaggle/working/runs/detect/train\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!yolo task=detect mode=train model=yolov8m.pt data=\"/kaggle/input/weapon-large-dataset/Weapon_Large_Dataset/data.yaml\" \\\n","    epochs=100 batch=16 imgsz=640 save=True save_period=-1 cache=False device=0 workers=8 \\\n","    project=None name=Weapon_detection exist_ok=False pretrained=True optimizer=SGD \\\n","    verbose=True seed=0 deterministic=True single_cls=True rect=False cos_lr=True close_mosaic=10 \\\n","    resume=False amp=True fraction=1.0 profile=False freeze=None multi_scale=False overlap_mask=True \\\n","    mask_ratio=4 dropout=0.1 val=True split=val save_json=False save_hybrid=False conf=0.3 iou=0.5 \\\n","    max_det=300 half=False dnn=False plots=True source=None vid_stride=1 stream_buffer=False \\\n","    visualize=False augment=True agnostic_nms=False classes=None retina_masks=False embed=None show=False \\\n","    save_frames=False save_txt=False save_conf=False save_crop=False show_labels=True show_conf=True \\\n","    show_boxes=True line_width=None format=torchscript keras=False optimize=False int8=False \\\n","    dynamic=False simplify=True opset=None workspace=4 nms=False lr0=0.001 lrf=0.2 momentum=0.9 \\\n","    weight_decay=0.0005 warmup_epochs=3.0 warmup_momentum=0.8 warmup_bias_lr=0.1 box=7.5 cls=0.5 \\\n","    dfl=1.5 pose=12.0 kobj=1.0 label_smoothing=0.05 nbs=64 hsv_h=0.015 hsv_s=0.7 hsv_v=0.4 \\\n","    degrees=0.0 translate=0.05 scale=0.5 shear=0.0 perspective=0.0 flipud=0.0 fliplr=0.5 bgr=0.0 \\\n","    mosaic=1 mixup=0.1 copy_paste=0.0 copy_paste_mode=flip auto_augment=None erasing=0.3 \\\n","    crop_fraction=1.0 cfg=None tracker=botsort.yaml"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-10-09T04:00:12.519370Z","iopub.status.busy":"2024-10-09T04:00:12.518882Z"}},"source":["# Resume training\n","!yolo detect train data= \"/kaggle/input/lab-dataset/data.yaml\" model= \"/kaggle/input/weapons/pytorch/default/1/best (3).pt\" resume=True"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!yolo detect train data= \"/kaggle/input/lab-dataset/data.yaml\" model= \"/kaggle/input/weapons/pytorch/default/1/best (3).pt\" resume=True"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Import necessary libraries\n","import cv2\n","from ultralytics import YOLO\n","import os\n","\n","# Load the YOLOv8 model (replace 'yolov8n.pt' with your custom model if needed)\n","model = YOLO('/kaggle/working/runs/detect/train2/weights/best.pt')  # Or 'yolov8s.pt', or your custom model path\n","\n","# Function to process an image and display/save the result\n","def process_image(image_path):\n","    # Read image\n","    img = cv2.imread(image_path)\n","    \n","    # Perform detection\n","    results = model(img)\n","    \n","    # Display the image with bounding boxes\n","    annotated_frame = results[0].plot()  # Plot the results\n","    \n","    # Save the output image in Kaggle's working directory\n","    output_image_path = os.path.join('/kaggle/working', 'output_image.jpg')\n","    cv2.imwrite(output_image_path, annotated_frame)\n","    print(f\"Annotated image saved at: {output_image_path}\")\n","\n","# Function to process a video, save the annotated output\n","def process_video(video_path, output_path):\n","    # Open video file\n","    cap = cv2.VideoCapture(video_path)\n","    \n","    # Get video properties (width, height, fps)\n","    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fps = int(cap.get(cv2.CAP_PROP_FPS))\n","\n","    # Define codec and create VideoWriter object for saving the output video\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4 format\n","    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        \n","        # Perform detection on the frame\n","        results = model(frame)\n","        \n","        # Annotate the frame with the detections\n","        annotated_frame = results[0].plot()\n","        \n","        # Write the annotated frame to the output video\n","        out.write(annotated_frame)\n","    \n","    # Release the resources\n","    cap.release()\n","    out.release()\n","    print(f\"Annotated video saved at: {output_path}\")\n","\n","# Set paths (Kaggle's input/output directories)\n","image_path = '/kaggle/input/your-dataset-directory/your-image.jpg'  # Update with your image file path\n","video_path = '/kaggle/input/weapon-detection-test-dataset/DARRA ADAM KHEL VLOGS.mp4'  # Update with your video file path\n","output_video_path = '/kaggle/working/output_video2.mp4'  # Output path in Kaggle's working directory\n","\n","# Process and save an image (you can comment this out if only processing video)\n","process_image(image_path)\n","\n","# Process and save a video\n","process_video(video_path, output_video_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T09:07:00.764596Z","iopub.status.busy":"2024-10-09T09:07:00.763741Z"},"trusted":true},"outputs":[],"source":["from IPython.display import Video\n","\n","# Path to your video file\n","video_path = '/kaggle/working/runs/detect/predict/Surveillance video_ Boy robs gas station fires shot.avi'\n","\n","# Display the video\n","Video(video_path, embed=True, width=600, height=400)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5757209,"sourceId":9538741,"sourceType":"datasetVersion"},{"datasetId":5878899,"sourceId":9630099,"sourceType":"datasetVersion"},{"datasetId":5884978,"sourceId":9638081,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
